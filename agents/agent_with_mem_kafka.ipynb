{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "611655cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching modules under: /workspaces/fraud_detection_demo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get project root: one level up from /agents\n",
    "PROJECT_ROOT = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    "\n",
    "# Ensure it's on sys.path\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Searching modules under:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d07c25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI seen by Settings: mongodb+srv://anant:pwd@cluster0.kzo3h.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\n"
     ]
    }
   ],
   "source": [
    "# first cell in the notebook\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# load .env explicitly (if you use python-dotenv)\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(dotenv_path=Path.cwd() / \".env\")  # or Path(\"..\") / \".env\" depending on your layout\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# (optional) set manually if needed\n",
    "# os.environ[\"MONGODB_URI\"] = \"mongodb+srv://...\"\n",
    "\n",
    "# NOW import settings\n",
    "from config.settings import Settings\n",
    "print(\"URI seen by Settings:\", getattr(Settings, \"MONGODB_URI\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d17ad776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.mongodb.aio import AsyncMongoDBSaver\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pymongo import MongoClient\n",
    "from models.transaction import Transaction\n",
    "from services.fraud_signature_service import FraudSignatureService\n",
    "from services.cloud_kafka_service import CloudKafkaService\n",
    "from typing import Dict, Any, List, Optional, Union\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "import logging\n",
    "import asyncio\n",
    "from config.settings import Settings\n",
    "from config.logger import get_logger\n",
    "from datetime import datetime\n",
    "from utils.print_helper import *\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06deb5c",
   "metadata": {},
   "source": [
    "### \n",
    "1. MongoDB Connection\n",
    "2. Encoding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dba2b7cb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "logger = get_logger(__name__)\n",
    "client = MongoClient(Settings.MONGODB_URI)\n",
    "encoder = SentenceTransformer(Settings.EMBEDDING_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa3de2ac",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def ensure_state(s: Union[\"WorkflowState\", dict]) -> \"WorkflowState\":\n",
    "    return s if isinstance(s, WorkflowState) else WorkflowState(**s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c3f93",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "Pydantic model\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "129872c4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class WorkflowState(BaseModel):\n",
    "    transaction: Transaction\n",
    "    duplicate_check: Optional[Dict[str, Any]] = None\n",
    "    fraud_analysis: Optional[Dict[str, Any]] = None\n",
    "    similarity_data: Optional[Dict[str, Any]] = None\n",
    "    recommendation: Optional[str] = None\n",
    "    storage_status: Optional[str] = None\n",
    "    errors: List[str] = Field(default_factory=list)  # avoid shared mutable default\n",
    "    agent_reflection: Optional[str] = None\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def convert_transaction_if_needed(cls, values):\n",
    "        txn = values.get(\"transaction\")\n",
    "        if isinstance(txn, dict):\n",
    "            values[\"transaction\"] = Transaction(**txn)\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ad980a1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_db():\n",
    "    return client[Settings.MONGODB_DATABASE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6f92b",
   "metadata": {},
   "source": [
    "### Duplicate check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b0f7c67",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def duplicate_check(state: WorkflowState) -> WorkflowState:\n",
    "    try:\n",
    "        transaction = state.transaction\n",
    "\n",
    "        def check_duplicate():\n",
    "            db = get_db()\n",
    "            return db[Settings.MONGODB_COLLECTION_CASES].count_documents(\n",
    "                {\"ip_address\": transaction.ip_address}\n",
    "            ) > 0\n",
    "\n",
    "        loop = asyncio.get_event_loop()\n",
    "        is_duplicate = await loop.run_in_executor(None, check_duplicate)\n",
    "\n",
    "        result = {\n",
    "            \"is_duplicate\": is_duplicate,\n",
    "            \"customer_id\": transaction.customer_id,\n",
    "            \"transaction_id\": transaction.transaction_id,\n",
    "            \"checked_at\": time.time(),  # epoch seconds (fix)\n",
    "            \"recommendation\": \"SKIP_PROCESSING\" if is_duplicate else \"CONTINUE_PROCESSING\"\n",
    "        }\n",
    "\n",
    "        if is_duplicate:\n",
    "            result[\"reason\"] = \"Duplicate complaint detected within 24 hours\"\n",
    "\n",
    "        state.duplicate_check = result\n",
    "        logger.info(f\"Duplicate check completed for {transaction.transaction_id}: {is_duplicate}\")\n",
    "\n",
    "        # Pretty print\n",
    "        pretty_duplicate(result)\n",
    "\n",
    "    except Exception as e:\n",
    "        state.errors.append(f\"duplicate_check error: {str(e)}\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58c7a3",
   "metadata": {},
   "source": [
    "### Fraud Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80c241ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def fraud_classification(state: WorkflowState) -> WorkflowState:\n",
    "    try:\n",
    "        amt = state.transaction.amount or 0\n",
    "        state.fraud_analysis = {\"is_fraud\": amt > 1000}\n",
    "        logger.info(f\"Fraud classification: {state.fraud_analysis}\")\n",
    "\n",
    "        # Pretty print\n",
    "        pretty_fraud(state.fraud_analysis, amt)\n",
    "\n",
    "    except Exception as e:\n",
    "        state.errors.append(f\"fraud_classification error: {str(e)}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0134d6c",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6df414c8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def similarity_search(state: WorkflowState) -> WorkflowState:\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        fs = FraudSignatureService()\n",
    "        signatures = fs.generate_fraud_signatures(state.transaction)\n",
    "\n",
    "        def encode():\n",
    "            return encoder.encode([\" \".join(signatures)])[0]\n",
    "\n",
    "        embedding = await loop.run_in_executor(None, encode)\n",
    "\n",
    "        def search():\n",
    "            db = get_db()\n",
    "            results = list(db[Settings.MONGODB_COLLECTION_SIGNATURES].aggregate([\n",
    "                {\"$vectorSearch\": {\n",
    "                    \"index\": Settings.VECTOR_INDEX_NAME,\n",
    "                    \"path\": \"embedding\",\n",
    "                    \"queryVector\": embedding.tolist(),\n",
    "                    \"numCandidates\": 50,\n",
    "                    \"limit\": 5,\n",
    "                }},\n",
    "                # If your server supports it, you can $project score explicitly:\n",
    "                # {\"$project\": {\"_id\": 1, \"transaction_id\": 1, \"signatures\": 1, \"score\": {\"$meta\": \"vectorSearchScore\"}}}\n",
    "            ]))\n",
    "\n",
    "            # Convert ObjectId to string for clean printing\n",
    "            for r in results:\n",
    "                if \"_id\" in r:\n",
    "                    r[\"_id\"] = str(r[\"_id\"])\n",
    "            return results\n",
    "\n",
    "        results = await loop.run_in_executor(None, search)\n",
    "\n",
    "        # Save both the results and the query signatures for printing\n",
    "        state.similarity_data = {\"similar_cases\": results, \"query_signatures\": signatures}\n",
    "\n",
    "        # Store signature for high-risk transactions\n",
    "        def insert_signature():\n",
    "            db = get_db()\n",
    "            db[Settings.MONGODB_COLLECTION_SIGNATURES].insert_one({\n",
    "                \"transaction_id\": state.transaction.transaction_id,\n",
    "                \"signatures\": signatures,\n",
    "                \"embedding\": embedding.tolist()\n",
    "            })\n",
    "\n",
    "        if state.fraud_analysis and state.fraud_analysis.get(\"is_fraud\"):\n",
    "            await loop.run_in_executor(None, insert_signature)\n",
    "            logger.info(f\"Stored fraud signature for {state.transaction.transaction_id}\")\n",
    "\n",
    "        # Pretty print\n",
    "        pretty_similarity(state.similarity_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        state.errors.append(f\"similarity_search error: {str(e)}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043d3a1",
   "metadata": {},
   "source": [
    "### LLM Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "661deb1d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def agent_reflection(state: WorkflowState) -> WorkflowState:\n",
    "    try:\n",
    "        # Use GPT-3.5-turbo for better rate limits and lower cost\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\", \n",
    "            temperature=0,\n",
    "            max_retries=3,\n",
    "            request_timeout=60,\n",
    "            max_tokens=200  # Significantly reduce response length\n",
    "        )\n",
    "        \n",
    "        # Create a much shorter, focused prompt\n",
    "        fraud_status = state.fraud_analysis.get(\"is_fraud\", False) if state.fraud_analysis else False\n",
    "        similar_count = len(state.similarity_data.get(\"similar_cases\", [])) if state.similarity_data else 0\n",
    "        \n",
    "        prompt = f\"\"\"Fraud detected: {fraud_status}\n",
    "Similar cases found: {similar_count}\n",
    "\n",
    "Brief analysis (max 100 words): What actions should be taken?\"\"\"\n",
    "        \n",
    "        # Add delay to prevent rate limiting\n",
    "        await asyncio.sleep(2)\n",
    "        \n",
    "        response = await llm.ainvoke(prompt)\n",
    "        state.agent_reflection = str(response.content if hasattr(response, \"content\") else response)\n",
    "        logger.info(\"Agent reflection completed\")\n",
    "        \n",
    "        # Pretty print\n",
    "        pretty_reflection(state.agent_reflection)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"agent_reflection error (continuing): {str(e)}\")\n",
    "        # Provide a simple fallback response\n",
    "        fraud_status = state.fraud_analysis.get(\"is_fraud\", False) if state.fraud_analysis else False\n",
    "        state.agent_reflection = (\n",
    "            \"Automatic analysis: High risk transaction - requires immediate review\"\n",
    "            if fraud_status else\n",
    "            \"Automatic analysis: Low risk transaction - standard processing\"\n",
    "        )\n",
    "        state.errors.append(f\"agent_reflection error: {str(e)}\")\n",
    "        pretty_reflection(state.agent_reflection)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644ab0f",
   "metadata": {},
   "source": [
    "### LLM Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a92602c7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def action_recommendation(state: WorkflowState) -> WorkflowState:\n",
    "    try:\n",
    "        # Use GPT-3.5-turbo for better rate limits and lower cost\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\", \n",
    "            temperature=0,\n",
    "            max_retries=3,\n",
    "            request_timeout=60,\n",
    "            max_tokens=150  # Significantly reduce response length\n",
    "        )\n",
    "        \n",
    "        # Create a much shorter, focused prompt\n",
    "        fraud_status = state.fraud_analysis.get(\"is_fraud\", False) if state.fraud_analysis else False\n",
    "        similar_count = len(state.similarity_data.get(\"similar_cases\", [])) if state.similarity_data else 0\n",
    "        \n",
    "        prompt = f\"\"\"Transaction risk: {'HIGH' if fraud_status else 'LOW'}\n",
    "Similar cases: {similar_count}\n",
    "\n",
    "Recommended action (max 50 words):\"\"\"\n",
    "        \n",
    "        # Add delay to prevent rate limiting\n",
    "        await asyncio.sleep(2)\n",
    "        \n",
    "        response = await llm.ainvoke(prompt)\n",
    "        state.recommendation = str(response.content if hasattr(response, \"content\") else response)\n",
    "        logger.info(\"Action recommendation completed\")\n",
    "        \n",
    "        # Pretty print\n",
    "        pretty_recommendation(state.recommendation)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"action_recommendation error (continuing): {str(e)}\")\n",
    "        # Provide a simple fallback response\n",
    "        fraud_status = state.fraud_analysis.get(\"is_fraud\", False) if state.fraud_analysis else False\n",
    "        if fraud_status:\n",
    "            state.recommendation = \"RECOMMENDED ACTION: Block transaction, investigate customer account, review for fraud patterns.\"\n",
    "        else:\n",
    "            state.recommendation = \"RECOMMENDED ACTION: Approve transaction, continue monitoring.\"\n",
    "        state.errors.append(f\"action_recommendation error: {str(e)}\")\n",
    "        pretty_recommendation(state.recommendation)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca24cc",
   "metadata": {},
   "source": [
    "### Store Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b905b6fe",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def store_transaction(state: WorkflowState) -> WorkflowState:\n",
    "    try:\n",
    "        def store():\n",
    "            db = get_db()\n",
    "            # Handle both Pydantic v1 and v2\n",
    "            if hasattr(state.transaction, 'model_dump'):\n",
    "                txn_dict = state.transaction.model_dump()\n",
    "            else:\n",
    "                txn_dict = state.transaction.dict()\n",
    "            db[Settings.MONGODB_COLLECTION_CASES].insert_one(txn_dict)\n",
    "\n",
    "        loop = asyncio.get_event_loop()\n",
    "        await loop.run_in_executor(None, store)\n",
    "        state.storage_status = \"stored\"\n",
    "        logger.info(f\"Transaction {state.transaction.transaction_id} stored successfully\")\n",
    "        \n",
    "        # Pretty print\n",
    "        pretty_storage(state.storage_status, state.transaction.transaction_id)\n",
    "        \n",
    "    except Exception as e:\n",
    "        state.errors.append(f\"storage error: {str(e)}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b9156",
   "metadata": {},
   "source": [
    "### Kafka Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1fbc859",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def publish_result(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Publish the complete workflow result to Kafka output topic\"\"\"\n",
    "    try:\n",
    "        # Helper function to serialize datetime objects\n",
    "        def serialize_datetime(obj):\n",
    "            if isinstance(obj, datetime):\n",
    "                return obj.isoformat() + \"Z\"\n",
    "            elif isinstance(obj, dict):\n",
    "                return {k: serialize_datetime(v) for k, v in obj.items()}\n",
    "            elif isinstance(obj, list):\n",
    "                return [serialize_datetime(item) for item in obj]\n",
    "            else:\n",
    "                return obj\n",
    "        \n",
    "        # Create a comprehensive result payload\n",
    "        result_payload = {\n",
    "            \"transaction_id\": state.transaction.transaction_id,\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "            \"transaction\": serialize_datetime(state.transaction.model_dump() if hasattr(state.transaction, 'model_dump') else state.transaction.dict()),\n",
    "            \"fraud_analysis\": serialize_datetime(state.fraud_analysis),\n",
    "            \"similarity_data\": serialize_datetime(state.similarity_data),\n",
    "            \"recommendation\": state.recommendation,\n",
    "            \"agent_reflection\": state.agent_reflection,\n",
    "            \"storage_status\": state.storage_status,\n",
    "            \"errors\": state.errors\n",
    "        }\n",
    "        \n",
    "        # Use the existing Kafka service to publish\n",
    "        kafka_service = CloudKafkaService()\n",
    "        success = kafka_service.publish_message(\n",
    "            key=state.transaction.transaction_id,\n",
    "            data=result_payload,\n",
    "            topic=Settings.KAFKA_OUTPUT_TOPIC\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            logger.info(f\"Published result for transaction {state.transaction.transaction_id}\")\n",
    "        else:\n",
    "            state.errors.append(\"Failed to publish result to Kafka\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        state.errors.append(f\"publish_result error: {str(e)}\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed794fa9",
   "metadata": {},
   "source": [
    "### Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a4621df",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def build_workflow(checkpointer):\n",
    "    \"\"\"Build the LangGraph workflow with MongoDB checkpointing\"\"\"\n",
    "    workflow = StateGraph(WorkflowState)\n",
    "\n",
    "    # Add nodes\n",
    "    workflow.add_node(\"duplicate\", duplicate_check)\n",
    "    workflow.add_node(\"classify\", fraud_classification)\n",
    "    workflow.add_node(\"similarity\", similarity_search)\n",
    "    workflow.add_node(\"reflect\", agent_reflection)\n",
    "    workflow.add_node(\"recommend\", action_recommendation)\n",
    "    workflow.add_node(\"store\", store_transaction)\n",
    "    workflow.add_node(\"publish\", publish_result)\n",
    "\n",
    "    # Define the workflow\n",
    "    workflow.set_entry_point(\"duplicate\")\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"duplicate\",\n",
    "        lambda s: \"skip\" if s.duplicate_check and s.duplicate_check.get(\"is_duplicate\") else \"classify\",\n",
    "        {\"skip\": \"publish\", \"classify\": \"classify\"}\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"classify\",\n",
    "        lambda s: \"similarity\" if s.fraud_analysis and s.fraud_analysis.get(\"is_fraud\") else \"publish\",\n",
    "        {\"similarity\": \"similarity\", \"publish\": \"publish\"}\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(\"similarity\", \"reflect\")\n",
    "    workflow.add_edge(\"reflect\", \"recommend\")\n",
    "    workflow.add_edge(\"recommend\", \"store\")\n",
    "    workflow.add_edge(\"store\", \"publish\")\n",
    "    workflow.add_edge(\"publish\", END)\n",
    "\n",
    "    # Compile with MongoDB checkpointer\n",
    "    return workflow.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c19ccd1f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def run_workflow_with_checkpoint(compiled_workflow, transaction_data: dict, thread_id: str):\n",
    "    \"\"\"Run workflow with proper checkpoint handling\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Check if there's an existing checkpoint\n",
    "        existing_state = await compiled_workflow.aget_state(config)\n",
    "        \n",
    "        if existing_state and existing_state.values:\n",
    "            logger.info(f\"Resuming workflow from checkpoint for thread: {thread_id}\")\n",
    "            final_state = await compiled_workflow.ainvoke(None, config=config)\n",
    "        else:\n",
    "            logger.info(f\"Starting new workflow for thread: {thread_id}\")\n",
    "            # Start fresh workflow\n",
    "            start_state = ensure_state({\"transaction\": transaction_data})\n",
    "            final_state = await compiled_workflow.ainvoke(start_state, config=config)\n",
    "        \n",
    "        # After END, ainvoke returns a dictâ€”hydrate for printing/return\n",
    "        hydrated = ensure_state(final_state)\n",
    "        pretty_final(hydrated)\n",
    "        return hydrated\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in workflow execution for {thread_id}: {e}\")\n",
    "        # If checkpoint resume fails, try starting fresh\n",
    "        try:\n",
    "            logger.info(f\"Attempting fresh start for thread: {thread_id}\")\n",
    "            start_state = ensure_state({\"transaction\": transaction_data})\n",
    "            final_state = await compiled_workflow.ainvoke(start_state, config=config)\n",
    "            hydrated = ensure_state(final_state)\n",
    "            pretty_final(hydrated)\n",
    "            return hydrated\n",
    "        except Exception as fresh_error:\n",
    "            logger.error(f\"Fresh start also failed for {thread_id}: {fresh_error}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64db4842",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def process_transaction_from_kafka(transaction: Transaction, compiled_workflow):\n",
    "    \"\"\"Process a single transaction from Kafka through the workflow with checkpointing\"\"\"\n",
    "    try:\n",
    "        thread_id = f\"txn_{transaction.transaction_id}\"\n",
    "        \n",
    "        # Convert Transaction object to dict for workflow processing\n",
    "        if hasattr(transaction, 'model_dump'):\n",
    "            transaction_dict = transaction.model_dump()\n",
    "        else:\n",
    "            transaction_dict = transaction.dict()\n",
    "        \n",
    "        final_state = await run_workflow_with_checkpoint(\n",
    "            compiled_workflow, \n",
    "            transaction_dict, \n",
    "            thread_id\n",
    "        )\n",
    "        \n",
    "        return final_state\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing transaction {transaction.transaction_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31b3e9ad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def kafka_transaction_callback(transaction: Transaction, compiled_workflow):\n",
    "    \"\"\"Async callback function for Kafka consumer to process transactions with checkpointing\"\"\"\n",
    "    try:\n",
    "        print(f\"\\nProcessing transaction from Kafka: {transaction.transaction_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        result = await process_transaction_from_kafka(transaction, compiled_workflow)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"Workflow completed successfully for transaction: {transaction.transaction_id}\")\n",
    "        else:\n",
    "            print(f\"Workflow failed for transaction: {transaction.transaction_id}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in Kafka callback: {e}\")\n",
    "        print(f\"Kafka callback error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e28befc1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def consume_transactions_async(kafka_service, compiled_workflow):\n",
    "    \"\"\"Async version of consume_transactions that processes messages asynchronously\"\"\"\n",
    "    try:\n",
    "        if not kafka_service.consumer:\n",
    "            kafka_service.create_consumer()\n",
    "        \n",
    "        # Setup schema registry if not already done\n",
    "        if not kafka_service.schema_registry_client:\n",
    "            kafka_service.setup_schema_registry()\n",
    " \n",
    "        poll_count = 0\n",
    "        while True:\n",
    "            try:\n",
    "                poll_count += 1\n",
    "                logger.info(f\"Poll #{poll_count} - waiting for message...\")\n",
    "                \n",
    "                msg = kafka_service.consumer.poll(timeout=1.0)\n",
    "                \n",
    "                if msg is None:\n",
    "                    logger.info(f\"   Poll #{poll_count}: No message received\")\n",
    "                    continue\n",
    "                \n",
    "                if msg.error():\n",
    "                    logger.error(f\"   Poll #{poll_count}: Consumer error: {msg.error()}\")\n",
    "                    continue\n",
    "                \n",
    "                # Parse message \n",
    "                message_bytes = msg.value()\n",
    "                logger.info(f\"   Message bytes: {message_bytes[:20]}... (first 20 bytes)\")\n",
    "\n",
    "                # Parse message using manual Schema Registry format detection\n",
    "                # Check if it's a Schema Registry format message\n",
    "                if len(message_bytes) >= 5 and message_bytes[0:2] == b'\\x00\\x00':\n",
    "                    # Schema Registry format: [0, 0, schema_id_high, schema_id_low, ...json_data]\n",
    "                    try:\n",
    "                        # Extract JSON data (skip the 5-byte header)\n",
    "                        json_data = message_bytes[5:].decode('utf-8')\n",
    "                        transaction_dict = json.loads(json_data)\n",
    "                    except Exception as manual_error:\n",
    "                        logger.error(f\"Manual Schema Registry parsing failed: {manual_error}\")\n",
    "                        continue\n",
    "                else:\n",
    "                    # Try plain JSON deserialization\n",
    "                    try:\n",
    "                        transaction_dict = json.loads(msg.value().decode('utf-8'))\n",
    "                    except UnicodeDecodeError as decode_error:\n",
    "                        logger.error(f\"Failed to decode message as UTF-8: {decode_error}\")\n",
    "                        logger.error(\"   Message appears to be binary but not Schema Registry format\")\n",
    "                        continue\n",
    "                    except json.JSONDecodeError as json_error:\n",
    "                        logger.error(f\"Failed to parse JSON: {json_error}\")\n",
    "                        continue\n",
    "                \n",
    "                try:\n",
    "                    transaction = Transaction(**transaction_dict)\n",
    "                    \n",
    "                    # Process transaction asynchronously\n",
    "                    await kafka_transaction_callback(transaction, compiled_workflow)\n",
    "                except Exception as transaction_error:\n",
    "                    logger.error(f\"Failed to create Transaction object: {transaction_error}\")\n",
    "                    logger.error(f\"   Transaction dict: {transaction_dict}\")\n",
    "                    continue\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                logger.info(\"Received keyboard interrupt, shutting down...\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in message processing loop: {e}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in async consumer: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b19c8a6e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Main execution function using async context manager with Kafka consumption\"\"\"\n",
    "    \n",
    "    # Use async context manager for MongoDB checkpointer\n",
    "    async with AsyncMongoDBSaver.from_conn_string(\n",
    "        conn_string=Settings.MONGODB_URI,\n",
    "        db_name=Settings.MONGODB_DATABASE,\n",
    "        collection_name=\"langgraph_checkpoints\"\n",
    "    ) as checkpointer:\n",
    "        \n",
    "        logger.info(\"MongoDB checkpointer initialized successfully\")\n",
    "        \n",
    "        try:\n",
    "            # Build the workflow with MongoDB checkpointing\n",
    "            compiled_workflow = build_workflow(checkpointer)\n",
    "            logger.info(\"Workflow compiled successfully with MongoDB checkpointer\")\n",
    "            \n",
    "            # Initialize Kafka service\n",
    "            kafka_service = CloudKafkaService()\n",
    "            \n",
    "            print(\"Starting Kafka consumer for fraud detection workflow with memory...\")\n",
    "            print(f\"Listening on topic: {Settings.KAFKA_TOPIC}\")\n",
    "            print(\"Press Ctrl+C to stop...\")\n",
    "            \n",
    "            # Start consuming transactions from Kafka asynchronously\n",
    "            await consume_transactions_async(kafka_service, compiled_workflow)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nShutting down...\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in main execution: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Clean up Kafka service\n",
    "            if 'kafka_service' in locals():\n",
    "                kafka_service.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21e74ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationFailure",
     "evalue": "Authentication failed., full error: {'ok': 0.0, 'errmsg': 'Authentication failed.', 'code': 18, 'codeName': 'AuthenticationFailed', '$clusterTime': {'clusterTime': Timestamp(1755170312, 1), 'signature': {'hash': b\"&h\\x0f\\xa8E\\xd1=\\xc9\\x8b\\xf3'\\xd8\\xc5\\xb5\\x08\\xd0\\x01\\x0e\\x03}\", 'keyId': 7506619706804011010}}, 'operationTime': Timestamp(1755170312, 1)}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationFailure\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m logging.basicConfig(level=logging.INFO)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Main execution function using async context manager with Kafka consumption\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Use async context manager for MongoDB checkpointer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m AsyncMongoDBSaver.from_conn_string(\n\u001b[32m      6\u001b[39m     conn_string=Settings.MONGODB_URI,\n\u001b[32m      7\u001b[39m     db_name=Settings.MONGODB_DATABASE,\n\u001b[32m      8\u001b[39m     collection_name=\u001b[33m\"\u001b[39m\u001b[33mlanggraph_checkpoints\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m checkpointer:\n\u001b[32m     11\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mMongoDB checkpointer initialized successfully\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     14\u001b[39m         \u001b[38;5;66;03m# Build the workflow with MongoDB checkpointing\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/contextlib.py:210\u001b[39m, in \u001b[36m_AsyncGeneratorContextManager.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m anext(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/langgraph/checkpoint/mongodb/aio.py:173\u001b[39m, in \u001b[36mAsyncMongoDBSaver.from_conn_string\u001b[39m\u001b[34m(cls, conn_string, db_name, checkpoint_collection_name, writes_collection_name, ttl, **kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m     client = AsyncIOMotorClient(\n\u001b[32m    160\u001b[39m         conn_string,\n\u001b[32m    161\u001b[39m         driver=DriverInfo(\n\u001b[32m    162\u001b[39m             name=\u001b[33m\"\u001b[39m\u001b[33mLanggraph\u001b[39m\u001b[33m\"\u001b[39m, version=version(\u001b[33m\"\u001b[39m\u001b[33mlanggraph-checkpoint-mongodb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    163\u001b[39m         ),\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m     saver = AsyncMongoDBSaver(\n\u001b[32m    166\u001b[39m         client,\n\u001b[32m    167\u001b[39m         db_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    171\u001b[39m         **kwargs,\n\u001b[32m    172\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m saver._setup()\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m saver\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/langgraph/checkpoint/mongodb/aio.py:107\u001b[39m, in \u001b[36mAsyncMongoDBSaver._setup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    103\u001b[39m     num_indexes = \u001b[38;5;28mlen\u001b[39m(\n\u001b[32m    104\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m (\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checkpoint_collection.list_indexes()).to_list()  \u001b[38;5;66;03m# type:ignore[misc]\u001b[39;00m\n\u001b[32m    105\u001b[39m     )\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     num_indexes = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checkpoint_collection.list_indexes().to_list())  \u001b[38;5;66;03m# type:ignore[union-attr]\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_indexes < \u001b[32m2\u001b[39m:\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checkpoint_collection.create_index(\n\u001b[32m    110\u001b[39m         keys=[(\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m), (\u001b[33m\"\u001b[39m\u001b[33mcheckpoint_ns\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m), (\u001b[33m\"\u001b[39m\u001b[33mcheckpoint_id\u001b[39m\u001b[33m\"\u001b[39m, -\u001b[32m1\u001b[39m)],\n\u001b[32m    111\u001b[39m         unique=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    112\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/motor/core.py:1696\u001b[39m, in \u001b[36mAgnosticBaseCursor._to_list\u001b[39m\u001b[34m(self, length, the_list, future, get_more_result)\u001b[39m\n\u001b[32m   1692\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_to_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, length, the_list, future, get_more_result):\n\u001b[32m   1693\u001b[39m     \u001b[38;5;66;03m# get_more_result is the result of self._get_more().\u001b[39;00m\n\u001b[32m   1694\u001b[39m     \u001b[38;5;66;03m# to_list_future will be the result of the user's to_list() call.\u001b[39;00m\n\u001b[32m   1695\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1696\u001b[39m         result = \u001b[43mget_more_result\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1697\u001b[39m         \u001b[38;5;66;03m# Return early if the task was cancelled.\u001b[39;00m\n\u001b[32m   1698\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m future.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/motor/core.py:1917\u001b[39m, in \u001b[36mAgnosticLatentCommandCursor._on_started\u001b[39m\u001b[34m(self, original_future, future)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_on_started\u001b[39m(\u001b[38;5;28mself\u001b[39m, original_future, future):\n\u001b[32m   1913\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1914\u001b[39m         \u001b[38;5;66;03m# \"result\" is a PyMongo command cursor from PyMongo's aggregate() or\u001b[39;00m\n\u001b[32m   1915\u001b[39m         \u001b[38;5;66;03m# aggregate_raw_batches(). Set its batch size from our latent\u001b[39;00m\n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# cursor's batch size.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1917\u001b[39m         pymongo_cursor = \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1918\u001b[39m         \u001b[38;5;28mself\u001b[39m.delegate = pymongo_cursor\n\u001b[32m   1919\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/collection.py:2518\u001b[39m, in \u001b[36mCollection.list_indexes\u001b[39m\u001b[34m(self, session, comment)\u001b[39m\n\u001b[32m   2491\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlist_indexes\u001b[39m(\n\u001b[32m   2492\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2493\u001b[39m     session: Optional[ClientSession] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2494\u001b[39m     comment: Optional[Any] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2495\u001b[39m ) -> CommandCursor[MutableMapping[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m   2496\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a cursor over the index documents for this collection.\u001b[39;00m\n\u001b[32m   2497\u001b[39m \n\u001b[32m   2498\u001b[39m \u001b[33;03m      >>> for index in db.test.list_indexes():\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2516\u001b[39m \u001b[33;03m    .. versionadded:: 3.0\u001b[39;00m\n\u001b[32m   2517\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_list_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/collection.py:2565\u001b[39m, in \u001b[36mCollection._list_indexes\u001b[39m\u001b[34m(self, session, comment)\u001b[39m\n\u001b[32m   2562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cmd_cursor\n\u001b[32m   2564\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._database.client._tmp_session(session, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_database\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_retryable_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_cmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_Op\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLIST_INDEXES\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/mongo_client.py:2026\u001b[39m, in \u001b[36mMongoClient._retryable_read\u001b[39m\u001b[34m(self, func, read_pref, session, operation, address, retryable, operation_id)\u001b[39m\n\u001b[32m   2021\u001b[39m \u001b[38;5;66;03m# Ensure that the client supports retrying on reads and there is no session in\u001b[39;00m\n\u001b[32m   2022\u001b[39m \u001b[38;5;66;03m# transaction, otherwise, we will not support retry behavior for this call.\u001b[39;00m\n\u001b[32m   2023\u001b[39m retryable = \u001b[38;5;28mbool\u001b[39m(\n\u001b[32m   2024\u001b[39m     retryable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.options.retry_reads \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (session \u001b[38;5;129;01mand\u001b[39;00m session.in_transaction)\n\u001b[32m   2025\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2029\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2030\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2031\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_read\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2032\u001b[39m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m=\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_pref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2034\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretryable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2035\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2036\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/_csot.py:119\u001b[39m, in \u001b[36mapply.<locals>.csot_wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[32m    118\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/mongo_client.py:1993\u001b[39m, in \u001b[36mMongoClient._retry_internal\u001b[39m\u001b[34m(self, func, session, bulk, operation, is_read, address, read_pref, retryable, operation_id)\u001b[39m\n\u001b[32m   1956\u001b[39m \u001b[38;5;129m@_csot\u001b[39m.apply\n\u001b[32m   1957\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_retry_internal\u001b[39m(\n\u001b[32m   1958\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1967\u001b[39m     operation_id: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1968\u001b[39m ) -> T:\n\u001b[32m   1969\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Internal retryable helper for all client transactions.\u001b[39;00m\n\u001b[32m   1970\u001b[39m \n\u001b[32m   1971\u001b[39m \u001b[33;03m    :param func: Callback function we want to retry\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1980\u001b[39m \u001b[33;03m    :return: Output of the calling func()\u001b[39;00m\n\u001b[32m   1981\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1982\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ClientConnectionRetryable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmongo_client\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbulk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbulk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1986\u001b[39m \u001b[43m        \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_read\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_read\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_pref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1990\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m=\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretryable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretryable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1992\u001b[39m \u001b[43m        \u001b[49m\u001b[43moperation_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1993\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/mongo_client.py:2730\u001b[39m, in \u001b[36m_ClientConnectionRetryable.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2728\u001b[39m \u001b[38;5;28mself\u001b[39m._check_last_error(check_csot=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2729\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2730\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_read \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._write()\n\u001b[32m   2731\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ServerSelectionTimeoutError:\n\u001b[32m   2732\u001b[39m     \u001b[38;5;66;03m# The application may think the write was never attempted\u001b[39;00m\n\u001b[32m   2733\u001b[39m     \u001b[38;5;66;03m# if we raise ServerSelectionTimeoutError on the retry\u001b[39;00m\n\u001b[32m   2734\u001b[39m     \u001b[38;5;66;03m# attempt. Raise the original exception instead.\u001b[39;00m\n\u001b[32m   2735\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_last_error()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/mongo_client.py:2877\u001b[39m, in \u001b[36m_ClientConnectionRetryable._read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2875\u001b[39m \u001b[38;5;28mself\u001b[39m._server = \u001b[38;5;28mself\u001b[39m._get_server()\n\u001b[32m   2876\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._read_pref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mRead Preference required on read calls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2877\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_conn_from_server\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_pref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mread_pref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2881\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrying\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retryable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2882\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_last_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/mongo_client.py:1846\u001b[39m, in \u001b[36mMongoClient._conn_from_server\u001b[39m\u001b[34m(self, read_preference, server, session)\u001b[39m\n\u001b[32m   1837\u001b[39m \u001b[38;5;66;03m# Get a connection for a server matching the read preference, and yield\u001b[39;00m\n\u001b[32m   1838\u001b[39m \u001b[38;5;66;03m# conn with the effective read preference. The Server Selection\u001b[39;00m\n\u001b[32m   1839\u001b[39m \u001b[38;5;66;03m# Spec says not to send any $readPreference to standalones and to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1843\u001b[39m \u001b[38;5;66;03m# NOTE: We already opened the Topology when selecting a server so there's no need\u001b[39;00m\n\u001b[32m   1844\u001b[39m \u001b[38;5;66;03m# to call _get_topology() again.\u001b[39;00m\n\u001b[32m   1845\u001b[39m single = \u001b[38;5;28mself\u001b[39m._topology.description.topology_type == TOPOLOGY_TYPE.Single\n\u001b[32m-> \u001b[39m\u001b[32m1846\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msingle\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_repl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43min_transaction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1849\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Use primary preferred to ensure any repl set member\u001b[39;49;00m\n\u001b[32m   1850\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# can handle the request.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/mongo_client.py:1756\u001b[39m, in \u001b[36mMongoClient._checkout\u001b[39m\u001b[34m(self, server, session)\u001b[39m\n\u001b[32m   1754\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m session._pinned_connection\n\u001b[32m   1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1756\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m=\u001b[49m\u001b[43merr_handler\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1757\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Pin this session to the selected server or connection.\u001b[39;49;00m\n\u001b[32m   1758\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1759\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_txn\u001b[49m\n\u001b[32m   1760\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1765\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1766\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1767\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_pin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/pool.py:1116\u001b[39m, in \u001b[36mPool.checkout\u001b[39m\u001b[34m(self, handler)\u001b[39m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enabled_for_logging \u001b[38;5;129;01mand\u001b[39;00m _CONNECTION_LOGGER.isEnabledFor(logging.DEBUG):\n\u001b[32m   1108\u001b[39m     _debug_log(\n\u001b[32m   1109\u001b[39m         _CONNECTION_LOGGER,\n\u001b[32m   1110\u001b[39m         message=_ConnectionStatusMessage.CHECKOUT_STARTED,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1113\u001b[39m         serverPort=\u001b[38;5;28mself\u001b[39m.address[\u001b[32m1\u001b[39m],\n\u001b[32m   1114\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckout_started_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1118\u001b[39m duration = time.monotonic() - checkout_started_time\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enabled_for_cmap:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/pool.py:1278\u001b[39m, in \u001b[36mPool._get_conn\u001b[39m\u001b[34m(self, checkout_started_time, handler)\u001b[39m\n\u001b[32m   1276\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# We need to create a new connection\u001b[39;00m\n\u001b[32m   1277\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1278\u001b[39m         conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1279\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1280\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._max_connecting_cond:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/pool.py:1070\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self, handler)\u001b[39m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m handler:\n\u001b[32m   1068\u001b[39m         handler.contribute_socket(conn, completed_handshake=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauthenticate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[38;5;66;03m# Catch KeyboardInterrupt, CancelledError, etc. and cleanup.\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/pool.py:523\u001b[39m, in \u001b[36mConnection.authenticate\u001b[39m\u001b[34m(self, reauthenticate)\u001b[39m\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m creds:\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpymongo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msynchronous\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auth\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauthenticate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreauthenticate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreauthenticate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28mself\u001b[39m.ready = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    525\u001b[39m duration = time.monotonic() - \u001b[38;5;28mself\u001b[39m.creation_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/auth.py:450\u001b[39m, in \u001b[36mauthenticate\u001b[39m\u001b[34m(credentials, conn, reauthenticate)\u001b[39m\n\u001b[32m    448\u001b[39m     _authenticate_oidc(credentials, conn, reauthenticate)\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     \u001b[43mauth_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/auth.py:353\u001b[39m, in \u001b[36m_authenticate_default\u001b[39m\u001b[34m(credentials, conn)\u001b[39m\n\u001b[32m    351\u001b[39m     mechs = (conn.command(source, cmd, publish_events=\u001b[38;5;28;01mFalse\u001b[39;00m)).get(\u001b[33m\"\u001b[39m\u001b[33msaslSupportedMechs\u001b[39m\u001b[33m\"\u001b[39m, [])\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mSCRAM-SHA-256\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mechs:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_authenticate_scram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSCRAM-SHA-256\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _authenticate_scram(credentials, conn, \u001b[33m\"\u001b[39m\u001b[33mSCRAM-SHA-1\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/auth.py:135\u001b[39m, in \u001b[36m_authenticate_scram\u001b[39m\u001b[34m(credentials, conn, mechanism)\u001b[39m\n\u001b[32m    128\u001b[39m server_sig = standard_b64encode(_hmac(server_key, auth_msg, digestmod).digest())\n\u001b[32m    130\u001b[39m cmd = {\n\u001b[32m    131\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msaslContinue\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m    132\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconversationId\u001b[39m\u001b[33m\"\u001b[39m: res[\u001b[33m\"\u001b[39m\u001b[33mconversationId\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    133\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m: Binary(client_final),\n\u001b[32m    134\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m res = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m parsed = _parse_scram_response(res[\u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hmac.compare_digest(parsed[\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mv\u001b[39m\u001b[33m\"\u001b[39m], server_sig):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/helpers.py:47\u001b[39m, in \u001b[36m_handle_reauth.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpymongo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msynchronous\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Connection\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m no_reauth:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/pool.py:411\u001b[39m, in \u001b[36mConnection.command\u001b[39m\u001b[34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[39m\n\u001b[32m    409\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_if_not_writable(unacknowledged)\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcommand\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdbname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mis_mongos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mread_preference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcodec_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallowable_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlisteners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_bson_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mread_concern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_write_concern_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_write_concern_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_op_msg\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mop_msg_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43munacknowledged\u001b[49m\u001b[43m=\u001b[49m\u001b[43munacknowledged\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_fields\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexhaust_allowed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexhaust_allowed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrite_concern\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_concern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (OperationFailure, NotPrimaryError):\n\u001b[32m    436\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/synchronous/network.py:212\u001b[39m, in \u001b[36mcommand\u001b[39m\u001b[34m(conn, dbname, spec, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed, write_concern)\u001b[39m\n\u001b[32m    210\u001b[39m             client._process_response(response_doc, session)\n\u001b[32m    211\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m check:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m             \u001b[43mhelpers_shared\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check_command_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m                \u001b[49m\u001b[43mresponse_doc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_wire_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m                \u001b[49m\u001b[43mallowable_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m                \u001b[49m\u001b[43mparse_write_concern_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_write_concern_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    219\u001b[39m     duration = datetime.datetime.now() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pymongo/helpers_shared.py:250\u001b[39m, in \u001b[36m_check_command_response\u001b[39m\u001b[34m(response, max_wire_version, allowable_errors, parse_write_concern_error)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m code == \u001b[32m43\u001b[39m:\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CursorNotFound(errmsg, code, response, max_wire_version)\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m OperationFailure(errmsg, code, response, max_wire_version)\n",
      "\u001b[31mOperationFailure\u001b[39m: Authentication failed., full error: {'ok': 0.0, 'errmsg': 'Authentication failed.', 'code': 18, 'codeName': 'AuthenticationFailed', '$clusterTime': {'clusterTime': Timestamp(1755170312, 1), 'signature': {'hash': b\"&h\\x0f\\xa8E\\xd1=\\xc9\\x8b\\xf3'\\xd8\\xc5\\xb5\\x08\\xd0\\x01\\x0e\\x03}\", 'keyId': 7506619706804011010}}, 'operationTime': Timestamp(1755170312, 1)}"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    # Run the main function\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9be3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
